{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%writefile Crawling_Utils.py\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def getSoup(url, parser):\n",
    "    hdr = {'User-Agent':'Mozilla/5.0'}\n",
    "    req = urllib.request.Request(url,headers=hdr)\n",
    "    with urllib.request.urlopen(req) as url:\n",
    "        doc = url.read()\n",
    "    return BeautifulSoup(doc, parser)\n",
    "\n",
    "# def getMetaData(url):\n",
    "    \n",
    "\n",
    "def getOkList(soup, isPC = 1):\n",
    "    okListTime = []\n",
    "    p = re.compile('\\d\\d\\d\\d/\\d\\d/\\d\\d \\d\\d:\\d\\d:\\d\\d')\n",
    "    if isPC:\n",
    "        okList = p.findall(soup.find_all(\"script\")[0].text) #PC:0, Mobile:-1\n",
    "    else:\n",
    "        okList = p.findall(soup.find_all(\"script\")[-1].text) #PC:0, Mobile:-1\n",
    "    okListTime = list(map(lambda x: datetime.strptime(x, '%Y/%m/%d %H:%M:%S'), okList ))\n",
    "    return okListTime\n",
    "  \n",
    "\n",
    "\n",
    "def getMemoList(soup):\n",
    "    script = soup.find_all(\"script\")\n",
    "    p = re.compile('parent_table = \".*?\"')\n",
    "    p = p.search(script[0].text)\n",
    "    parent_table = script[0].text[p.start():p.end()]\n",
    "    parent_table = parent_table[16:-1]\n",
    "\n",
    "    p = re.compile('parent_id = \".*?\"')\n",
    "    p = p.search(script[0].text)\n",
    "    parent_id = script[0].text[p.start():p.end()]\n",
    "    parent_id = parent_id[13:-1]\n",
    "    memo_url = \"/board/ajax_memo_list.php?parent_table=\" + parent_table + \"&parent_id=\" + parent_id;\n",
    "    memo_url = 'http://www.todayhumor.co.kr' + memo_url\n",
    "#     print(memo_url)\n",
    "\n",
    "    memo_soup =  getSoup(memo_url, \"html.parser\")\n",
    "#     memoData = dict()\n",
    "    memoList = []\n",
    "    memos = json.loads(memo_soup.text)['memos']\n",
    "    bestTime = 0\n",
    "    bObTime = 0\n",
    "    for memo in memos:\n",
    "        if 'MOVE_HUMORBEST' in memo['memo']:\n",
    "            bestTime = datetime.strptime(memo['date'], '%Y-%m-%d %H:%M:%S')\n",
    "        elif 'MOVE_BESTOFBEST' in memo['memo']:\n",
    "            bObTime = datetime.strptime(memo['date'], '%Y-%m-%d %H:%M:%S')\n",
    "        else:\n",
    "            date = datetime.strptime(memo['date'], '%Y-%m-%d %H:%M:%S')\n",
    "            memoList.append(date)\n",
    "#             date = memo['date']\n",
    "#             memoData[date] = [int(memo['ok']), int(memo['nok'])]\n",
    "    return memoList\n",
    "#     json.loads(memo_soup.text)['memos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = \"http://www.todayhumor.co.kr/board/view.php?table=bestofbest&no=288310&s_no=288310&page=1\"\n",
    "\n",
    "soup = getSoup(url, \"html.parser\")\n",
    "okList = getOkList(soup)\n",
    "(bTime,bobTime,memoList) = getMemoList(soup)\n",
    "\n",
    "writerInfoContents = soup.find_all(\"div\", class_=\"writerInfoContents\")\n",
    "divTags = writerInfoContents[0].find_all(\"div\")\n",
    "if len(divTags) is 10:\n",
    "    postTime = datetime.strptime(divTags[7].text.split(' : ')[1], '%Y/%m/%d %H:%M:%S')  # 게시 시간\n",
    "else:\n",
    "    postTime = datetime.strptime(divTags[6].text.split(' : ')[1], '%Y/%m/%d %H:%M:%S')  # 게시 시간\n",
    "    \n",
    "ok_time = list(map(lambda x: (x - postTime).total_seconds()/3600.0, okList[:50]))\n",
    "memo_time = list(map(lambda x: (x - postTime).total_seconds()/3600.0, memoList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(divTags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "fig1, (ax1) = plt.subplots(nrows=1, ncols=1, sharex=False)\n",
    "ax1.plot(ok_time, np.arange(1, len(ok_time)+1), 'g+-', label='ok', linewidth=1)\n",
    "ax1.set_ylabel('ok', color='g')\n",
    "ax1.tick_params(axis='x', colors='w')\n",
    "ax1.tick_params(axis='y', colors='g')\n",
    "ax1.set_xlabel('time(hour)')\n",
    "\n",
    "ax2 = ax1.twinx() \n",
    "ax2.plot(memo_time, np.arange(1, len(memo_time)+1), 'rx-', label='ok', linewidth=1)\n",
    "ax2.set_ylabel('memo', color='r')\n",
    "ax2.tick_params(axis='y', colors='red')\n",
    "ax2.set_xlim(0, ok_time[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax2.yaxis.get_ticklabels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "article_no = np.random.randint(250000,288325, size=10)\n",
    "\n",
    "dbForOk = dict()\n",
    "for i in article_no:\n",
    "    url = 'http://m.todayhumor.co.kr/view.php?table=bestofbest&no={}'.format(i)\n",
    "    print(url)\n",
    "    soup = getSoup(url, 'html.parser')\n",
    "#     if not len(soup.find_all('title')): continue\n",
    "    okList = getOkList(soup, isPC = 0)\n",
    "    postTime = datetime.strptime(soup.find_all('span', class_=\"view_wdate\")[0].text, '%Y/%m/%d %H:%M:%S')\n",
    "    okTime = list(map(lambda x: (x - postTime).total_seconds(), okList))\n",
    "#     <span class=\"view_wdate\">2016/12/08 22:41:06</span>\n",
    "    dbForOk[i] = okTime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open('db_bob_oks.pkl', 'wb') as f:\n",
    "    pkl.dump(dbForOk, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('db_bob_oks.pkl', 'rb') as f:\n",
    "    a = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'getSoup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-70e5dfd92cc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgetSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://m.todayhumor.co.kr/view.php?table=humorbest&no=1348480&page=1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mviewSubjectDiv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"div\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mviewSubjectDiv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'getSoup' is not defined"
     ]
    }
   ],
   "source": [
    "getSoup('http://m.todayhumor.co.kr/view.php?table=humorbest&no=1348480&page=1', 'html.parser')\n",
    "viewSubjectDiv = soup.find_all(\"div\")\n",
    "viewSubjectDiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame.from_dict(a, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://m.todayhumor.co.kr/view.php?table=humorbest&no=1348480&page=1'\n",
    "hdr = {'User-Agent':'Mozilla/5.0'}\n",
    "proxies = {'html', 'http://deng.in.net'}\n",
    "req = urllib.request.Request(url,headers=hdr)\n",
    "doc = \"\"\n",
    "with urllib.request.urlopen(req, ) as url:\n",
    "    doc = url.read()\n",
    "\n",
    "soup = BeautifulSoup(doc, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'http://www.todayhumor.co.kr/board/view.php?table=sisa&no=814032'\n",
    "\n",
    "infos = ['contentID', 'writerName', 'writerSignInDate', 'writerSignInDate', 'writerVisitingCount',\n",
    "        'recommendCount', 'viewCount', 'memoCount' , 'postTime', 'normalPostCount', 'bestPostCount', 'BOBPostCount',\n",
    "        'board', 'title', 'changjakOption', 'permOption', 'prohibitBestOption', 'prohibitBOBOption', 'prohibitBoninOption', \n",
    "        'prohibitOutsidePermOption', 'imgCount', 'videoCount',  'youtubeCount', 'textLineCount', \n",
    "        'okTime', 'memoTime' ]\n",
    "\n",
    "hdr = {'User-Agent':'Mozilla/5.0'}\n",
    "req = urllib.request.Request(url,headers=hdr)\n",
    "\n",
    "doc = \"\"\n",
    "with urllib.request.urlopen(req) as url:\n",
    "    doc = url.read()\n",
    "\n",
    "soup = BeautifulSoup(doc, \"html.parser\")\n",
    "\n",
    "## get Writer Infomation\n",
    "writerInfoContents = soup.find_all(\"div\", class_=\"writerInfoContents\")\n",
    "divTags = writerInfoContents[0].find_all(\"div\")\n",
    "\n",
    "contentID = divTags[0].text.split(' : ')[1]\n",
    "writerName = (divTags[1].find_all(\"b\"))[0].text   # 글쓴이 닉네임\n",
    "writerInfo_ = (divTags[1].find_all(\"span\"))[-1].text\n",
    "writerSignInDate = re.split(':| |\\)',writerInfo_)[1]   # 글쓴이 가입 날짜\n",
    "writerVisitingCount = re.split(':| |\\)',writerInfo_)[3]  # 방문 횟수\n",
    "recommendCount = divTags[2].find_all(\"span\")[0].text   # 추천수\n",
    "viewCount = divTags[3].text.split(' : ')[1]            # 조회수 \n",
    "memoCount = re.split(' : |개',divTags[5].text)[1]   # 댓글 수 \n",
    "# BOBTime = divTags[6].text.split(' : ')[1]              # 베스트 등록 시간\n",
    "postTime = divTags[6].text.split(' : ')[1]             # 게시 시간\n",
    "\n",
    "#### 게시자의 다른 글 개수 ####\n",
    "baseURL = \"http://www.todayhumor.co.kr/board/\"\n",
    "writerProfileURLSuffix = divTags[1].find_all(\"a\")[0][\"href\"]\n",
    "writerProfileURL = baseURL + writerProfileURLSuffix\n",
    "writerProfileReq = urllib.request.Request(writerProfileURL,headers=hdr)\n",
    "\n",
    "writerProfileDoc = \"\"\n",
    "with urllib.request.urlopen(writerProfileReq) as url:\n",
    "    writerProfileDoc = url.read()\n",
    "\n",
    "writerProfileSoup = BeautifulSoup(writerProfileDoc, \"html.parser\")    \n",
    "table_list = writerProfileSoup.find_all(\"table\", class_=\"table_list\")\n",
    "normalPostCount = table_list[0].find(\"a\").text         # 유저가 쓴 글 개수\n",
    "\n",
    "baseURL = \"http://www.todayhumor.co.kr\"\n",
    "member_menu_box = writerProfileSoup.find_all(\"div\", class_=\"member_menu_box\")\n",
    "writerProfileURLs = member_menu_box[0].find_all(\"a\")\n",
    "writerProfileBestURL = baseURL + writerProfileURLs[1][\"href\"]\n",
    "writerProfileBOBURL = baseURL + writerProfileURLs[2][\"href\"]\n",
    "\n",
    "writerProfileReq = urllib.request.Request(writerProfileBestURL,headers=hdr)\n",
    "writerProfileDoc = \"\"\n",
    "with urllib.request.urlopen(writerProfileReq) as url:\n",
    "    writerProfileDoc = url.read()\n",
    "\n",
    "writerProfileSoup = BeautifulSoup(writerProfileDoc, \"html.parser\")    \n",
    "table_list = writerProfileSoup.find_all(\"table\", class_=\"table_list\")\n",
    "bestPostCount = table_list[0].find(\"a\").text            # 유저가 쓴 베스트 개수\n",
    "\n",
    "writerProfileReq = urllib.request.Request(writerProfileBOBURL,headers=hdr)\n",
    "writerProfileDoc = \"\"\n",
    "with urllib.request.urlopen(writerProfileReq) as url:\n",
    "    writerProfileDoc = url.read()\n",
    "\n",
    "writerProfileSoup = BeautifulSoup(writerProfileDoc, \"html.parser\")    \n",
    "table_list = writerProfileSoup.find_all(\"table\", class_=\"table_list\")\n",
    "BOBPostCount = table_list[0].find(\"a\").text             # 유저가 쓴 베오베 개수\n",
    "\n",
    "################################\n",
    "\n",
    "## get Bulletin board Info\n",
    "viewSubjectDiv = soup.find_all(\"div\", class_=\"viewSubjectDiv\")\n",
    "\n",
    "board = viewSubjectDiv[0].find_all(\"span\")[0][\"class\"][1]    # 게시판 이름 \n",
    "title = viewSubjectDiv[0].find_all(\"div\")[0].text.strip()         # 제목\n",
    "\n",
    "## post option : 창작글, 펌글, 베스트 금지, 베오베 금지, 본인삭제금지, 외부펌 금지\n",
    "contentContainer = soup.find_all(\"div\", class_=\"contentContainer\")\n",
    "postOption = contentContainer[0].find_all(\"table\")\n",
    "\n",
    "changjakOption = False # 창작글\n",
    "permOption = False # 펌글\n",
    "prohibitBestOption = False # 베스트 금지\n",
    "prohibitBOBOption = False # 베오베 금지\n",
    "prohibitBoninOption = False # 본인삭제 금지\n",
    "prohibitOutsidePermOption = False # 외부펌 금지\n",
    "\n",
    "\n",
    "if len(postOption) is 2 :  # 첫 <table>은 글 옵션 두번째 <table>은 출처. 즉 테이블이 1개이면 출처만 있고 옵션이 없음\n",
    "\n",
    "    options = postOption[0].find_all(\"li\")\n",
    "\n",
    "    for option in options : \n",
    "        optionName = option.find_all(\"div\")[1].text\n",
    "        if optionName == \"창작글\" :\n",
    "            changjakOption = True\n",
    "        elif optionName == \"펌글\" :\n",
    "            permOption = True\n",
    "        elif optionName == \"베스트금지\" :\n",
    "            prohibitBestOption = True\n",
    "        elif optionName == \"베오베금지\" :\n",
    "            prohibitBOBOption = True\n",
    "        elif optionName == \"본인삭제금지\" :\n",
    "            prohibitBoninOption = True\n",
    "        elif optionName == \"외부펌금지\" :\n",
    "            prohibitOutsidePermOption = True    \n",
    "\n",
    "## 본문 내용 가져오기\n",
    "# 구해야 할것 :  이미지 개수, 동영상 유무(youtube or 움짤), 텍스트 길이, 키워드\n",
    "\n",
    "viewContent = soup.find_all(\"div\", class_=\"viewContent\")\n",
    "imgs = viewContent[0].find_all(\"img\") # 본문 삽입된 이미지들\n",
    "videos = viewContent[0].find_all(\"video\")\n",
    "youtubes = viewContent[0].find_all(\"iframe\")\n",
    "texts = viewContent[0].find_all(\"div\")\n",
    "\n",
    "textData = []\n",
    "for text in texts :\n",
    "    if (text.text) :\n",
    "        textData.append(text.text)\n",
    "\n",
    "imgCount = len(imgs)   # 이미지 카운트\n",
    "videoCount = len(videos)   # 움짤 카운트\n",
    "youtubeCount = len(youtubes)   # 유투브(iframe) 개수\n",
    "textLineCount = len(textData)   # 텍스트 줄 수\n",
    "\n",
    "okList = getOkList(soup)\n",
    "postTime = datetime.strptime(postTime, '%Y/%m/%d %H:%M:%S')\n",
    "okTime = list(map(lambda x: (x - postTime).total_seconds(), okList))\n",
    "memoList = getMemoList(soup)\n",
    "memoTime = list(map(lambda x: (x - postTime).total_seconds(), memoList))\n",
    "\n",
    "import collections\n",
    "articleInfo = collections.OrderedDict.fromkeys(infos)\n",
    "for entity in infos:\n",
    "    exec(\"articleInfo['{}'] = {}\".format(entity, entity))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>contentID</th>\n",
       "      <td>sisa_814032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>writerName</th>\n",
       "      <td>mangnani2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>writerSignInDate</th>\n",
       "      <td>2011-09-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>writerVisitingCount</th>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recommendCount</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>viewCount</th>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commentCount</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postTime</th>\n",
       "      <td>2016-12-10 02:07:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normalPostCount</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bestPostCount</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOBPostCount</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>board</th>\n",
       "      <td>sisa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>일해라 유시민. 다음 정권 때는 반드시 부려먹어야 할 사람임.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>changjakOption</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>permOption</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prohibitBestOption</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prohibitBOBOption</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prohibitBoninOption</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prohibitOutsidePermOption</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imgCount</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>videoCount</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youtubeCount</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textLineCount</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>okTime</th>\n",
       "      <td>[239.0, 271.0, 496.0, 655.0, 698.0, 884.0, 132...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>memoTime</th>\n",
       "      <td>[791.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           0\n",
       "contentID                                                        sisa_814032\n",
       "writerName                                                         mangnani2\n",
       "writerSignInDate                                                  2011-09-04\n",
       "writerVisitingCount                                                      397\n",
       "recommendCount                                                             7\n",
       "viewCount                                                                231\n",
       "commentCount                                                               1\n",
       "postTime                                                 2016-12-10 02:07:31\n",
       "normalPostCount                                                           66\n",
       "bestPostCount                                                              2\n",
       "BOBPostCount                                                               1\n",
       "board                                                                   sisa\n",
       "title                                     일해라 유시민. 다음 정권 때는 반드시 부려먹어야 할 사람임.\n",
       "changjakOption                                                         False\n",
       "permOption                                                             False\n",
       "prohibitBestOption                                                     False\n",
       "prohibitBOBOption                                                      False\n",
       "prohibitBoninOption                                                    False\n",
       "prohibitOutsidePermOption                                              False\n",
       "imgCount                                                                   0\n",
       "videoCount                                                                 0\n",
       "youtubeCount                                                               1\n",
       "textLineCount                                                             19\n",
       "okTime                     [239.0, 271.0, 496.0, 655.0, 698.0, 884.0, 132...\n",
       "memoTime                                                             [791.0]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame.from_dict(articleInfo,orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
